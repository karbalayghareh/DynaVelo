{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DynaVelo Demo\n",
    "\n",
    "#### Usage\n",
    "Two adata files are required: adata_rna and adata_atac. The first adata contains preprocessed RNA expression values and RNA velocity estimates from scVelo. As RNA velocities are prone to error and sensitive to gene sets, we have to first check if the overall trajectories make biological sense. The second adata contains TF motif accessibility z-scores from chromVAR. The shape of adata_rna is [n_cells, n_genes], and the shape of adata_atac is [n_cells, n_tfs].\n",
    "\n",
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "dataset_name = 'Ben'\n",
    "#sample_list = ['WT-3', 'WT-13', 'Icn2Het-2', 'Icn2Het-10', 'SpenHet-1-2', 'SpenHet-15', 'SpenHet-Icn2Het-8', 'SpenHet-Icn2Het-12']\n",
    "sample_name = 'Icn2Het-2'\n",
    "\n",
    "adata_rna = sc.read_h5ad(f\"/mnt/storage/Ben_data/analysis/outs/RNAMatrix/dynavelo/RNA_Matrix_{sample_name}_AiBC.h5ad\")\n",
    "adata_atac = sc.read_h5ad(f\"/mnt/storage/Ben_data/analysis/outs/MotifMatrix/dynavelo/MotifMatrix_{sample_name}_AiBC.h5ad\")\n",
    "\n",
    "assert all(adata_rna.obs_names == adata_atac.obs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prememory_Memory    5098\n",
       "Prememory_Naive      742\n",
       "CC_Rec               269\n",
       "Plasma_cell           67\n",
       "Recycling             40\n",
       "CB_S_G2M              35\n",
       "CB_Rec_Sphase         10\n",
       "Name: fine.celltype, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.obs['fine.celltype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3_AiBC    2843\n",
       "0_AiBC    2066\n",
       "7_AiBC     762\n",
       "9_AiBC     557\n",
       "8_AiBC      33\n",
       "Name: anno_clusters, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_rna.obs['anno_clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prememory_Memory    5098\n",
       "Prememory_Naive      742\n",
       "CC_Rec               269\n",
       "Plasma_cell           67\n",
       "Recycling             40\n",
       "CB_S_G2M              35\n",
       "CB_Rec_Sphase         10\n",
       "Name: fine.celltype, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_atac.obs['fine.celltype'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build datasets and dataloaders\n",
    "We first build Pytorch datasets and dataloaders from adata_rna and adata_atac to be used for training. MultiomeDataset is used to create the custom datasets. We randomly allocate 10% of the cells for the test and the rest for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../dynavelo\")\n",
    "from dynavelo.models import MultiomeDataset\n",
    "from dynavelo.models import DynaVelo\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# set gpu\n",
    "gpu = 1\n",
    "device = torch.device('cuda:' + str(gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# datasets and dataloaders\n",
    "dataset = MultiomeDataset(adata_rna, adata_atac, use_weights=False)\n",
    "N_test = int(0.1 * len(dataset))\n",
    "idx_random = np.random.permutation(len(dataset))\n",
    "idx_test = idx_random[:N_test]\n",
    "idx_train = idx_random[N_test:]\n",
    "dataset_train = MultiomeDataset(adata_rna[idx_train], adata_atac[idx_train], use_weights=False)\n",
    "dataset_test = MultiomeDataset(adata_rna[idx_test], adata_atac[idx_test], use_weights=False)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=256, shuffle=True, num_workers=0, drop_last=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=256, shuffle=False, num_workers=0)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate DynaVelo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters func:  495865\n",
      "encoder_net_x.0.weight torch.Size([50, 2631]) torch.float32\n",
      "encoder_net_x.0.weight Parameter containing:\n",
      "tensor([[-0.0001,  0.0105, -0.0160,  ..., -0.0036,  0.0012, -0.0064],\n",
      "        [-0.0071, -0.0168,  0.0011,  ...,  0.0045,  0.0072, -0.0139],\n",
      "        [ 0.0153,  0.0139, -0.0059,  ...,  0.0020, -0.0052,  0.0025],\n",
      "        ...,\n",
      "        [ 0.0146, -0.0186,  0.0096,  ...,  0.0194, -0.0164, -0.0175],\n",
      "        [-0.0137, -0.0035, -0.0165,  ..., -0.0160, -0.0098,  0.0137],\n",
      "        [-0.0064, -0.0171, -0.0091,  ..., -0.0033, -0.0129, -0.0105]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "encoder_net_x.0.bias torch.Size([50]) torch.float32\n",
      "encoder_net_x.0.bias Parameter containing:\n",
      "tensor([-9.7715e-03,  1.2772e-02,  1.8205e-02, -1.1239e-02, -1.7011e-02,\n",
      "         8.4122e-03,  1.1611e-02, -2.6513e-03, -1.4230e-02,  1.9178e-02,\n",
      "        -1.4118e-02, -5.2934e-03, -1.0111e-02, -2.4669e-03, -1.4569e-02,\n",
      "         1.0251e-02,  6.7808e-03, -6.1193e-03,  1.1878e-05,  1.8734e-02,\n",
      "         4.3591e-03, -1.6158e-02,  1.5792e-02, -4.5895e-03, -1.3404e-02,\n",
      "        -4.5792e-03,  9.6399e-03,  5.5207e-04, -1.4134e-02,  1.1683e-02,\n",
      "         6.3592e-03,  1.8128e-02,  2.8500e-03,  1.4759e-02,  6.0941e-03,\n",
      "         1.8648e-02, -1.6211e-02,  7.3795e-03, -2.8837e-03,  8.9071e-03,\n",
      "        -6.0940e-03,  2.9485e-03, -1.4181e-02,  7.8670e-05,  3.4952e-03,\n",
      "         1.4679e-02,  1.3654e-02,  2.6738e-03,  1.7618e-02, -6.2971e-03],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "encoder_net_y.0.weight torch.Size([50, 182]) torch.float32\n",
      "encoder_net_y.0.weight Parameter containing:\n",
      "tensor([[ 0.0606, -0.0574,  0.0177,  ..., -0.0271, -0.0327,  0.0645],\n",
      "        [ 0.0143,  0.0657,  0.0026,  ...,  0.0498, -0.0552, -0.0711],\n",
      "        [ 0.0387,  0.0573, -0.0724,  ...,  0.0269,  0.0433,  0.0435],\n",
      "        ...,\n",
      "        [ 0.0356,  0.0711, -0.0383,  ...,  0.0167, -0.0186,  0.0384],\n",
      "        [ 0.0298, -0.0252,  0.0307,  ...,  0.0040, -0.0690, -0.0574],\n",
      "        [-0.0189,  0.0591, -0.0259,  ..., -0.0374, -0.0236, -0.0501]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "encoder_net_y.0.bias torch.Size([50]) torch.float32\n",
      "encoder_net_y.0.bias Parameter containing:\n",
      "tensor([-0.0433,  0.0058,  0.0284,  0.0438, -0.0022,  0.0100,  0.0190,  0.0625,\n",
      "         0.0231, -0.0504, -0.0342, -0.0709,  0.0332, -0.0146, -0.0566,  0.0694,\n",
      "         0.0671, -0.0149,  0.0473, -0.0284, -0.0433, -0.0036, -0.0501, -0.0107,\n",
      "        -0.0642,  0.0353, -0.0385, -0.0055, -0.0070,  0.0655,  0.0250, -0.0393,\n",
      "        -0.0377, -0.0715,  0.0094, -0.0735, -0.0347,  0.0112,  0.0046,  0.0202,\n",
      "        -0.0267,  0.0446, -0.0720, -0.0649, -0.0583, -0.0522, -0.0196, -0.0051,\n",
      "         0.0276, -0.0035], device='cuda:1', requires_grad=True)\n",
      "encoder_net_tx.0.weight torch.Size([50, 2631]) torch.float32\n",
      "encoder_net_tx.0.weight Parameter containing:\n",
      "tensor([[-0.0069,  0.0073,  0.0063,  ...,  0.0179, -0.0138, -0.0050],\n",
      "        [ 0.0036, -0.0177, -0.0151,  ...,  0.0162,  0.0114, -0.0116],\n",
      "        [ 0.0047, -0.0023, -0.0022,  ..., -0.0116,  0.0146, -0.0111],\n",
      "        ...,\n",
      "        [ 0.0141,  0.0161, -0.0086,  ...,  0.0150,  0.0116,  0.0158],\n",
      "        [-0.0160,  0.0163, -0.0011,  ...,  0.0017,  0.0079, -0.0044],\n",
      "        [-0.0019, -0.0193,  0.0039,  ...,  0.0083,  0.0167, -0.0106]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "encoder_net_tx.0.bias torch.Size([50]) torch.float32\n",
      "encoder_net_tx.0.bias Parameter containing:\n",
      "tensor([-0.0152,  0.0053,  0.0159, -0.0096, -0.0185,  0.0006,  0.0066, -0.0191,\n",
      "         0.0076,  0.0008, -0.0101, -0.0132,  0.0106,  0.0027, -0.0115, -0.0082,\n",
      "         0.0108,  0.0147,  0.0096, -0.0175,  0.0163,  0.0171,  0.0195,  0.0153,\n",
      "        -0.0079,  0.0144,  0.0077,  0.0077, -0.0120, -0.0025,  0.0191, -0.0146,\n",
      "         0.0153, -0.0188,  0.0162, -0.0009, -0.0052, -0.0159, -0.0166, -0.0138,\n",
      "         0.0108,  0.0133, -0.0093,  0.0182, -0.0155, -0.0092,  0.0002, -0.0029,\n",
      "        -0.0146, -0.0059], device='cuda:1', requires_grad=True)\n",
      "encoder_net_ty.0.weight torch.Size([50, 182]) torch.float32\n",
      "encoder_net_ty.0.weight Parameter containing:\n",
      "tensor([[-0.0180, -0.0483, -0.0122,  ..., -0.0105, -0.0349, -0.0363],\n",
      "        [-0.0570, -0.0231,  0.0663,  ...,  0.0062, -0.0441,  0.0140],\n",
      "        [-0.0119, -0.0300,  0.0731,  ..., -0.0030,  0.0039,  0.0619],\n",
      "        ...,\n",
      "        [-0.0435, -0.0280,  0.0036,  ...,  0.0511,  0.0557,  0.0486],\n",
      "        [ 0.0635,  0.0270,  0.0526,  ...,  0.0555, -0.0318,  0.0173],\n",
      "        [ 0.0491,  0.0142,  0.0618,  ...,  0.0543,  0.0175, -0.0564]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "encoder_net_ty.0.bias torch.Size([50]) torch.float32\n",
      "encoder_net_ty.0.bias Parameter containing:\n",
      "tensor([-0.0125,  0.0236,  0.0581,  0.0455,  0.0317,  0.0410, -0.0631, -0.0584,\n",
      "        -0.0575,  0.0306, -0.0289, -0.0329, -0.0640,  0.0148,  0.0009, -0.0692,\n",
      "         0.0481, -0.0570, -0.0639,  0.0739,  0.0114, -0.0166, -0.0277, -0.0133,\n",
      "        -0.0052, -0.0304, -0.0143, -0.0505, -0.0209, -0.0658,  0.0415,  0.0739,\n",
      "         0.0091,  0.0541,  0.0178, -0.0629, -0.0215,  0.0640, -0.0257, -0.0517,\n",
      "        -0.0158, -0.0009, -0.0289,  0.0331, -0.0684, -0.0239,  0.0411,  0.0362,\n",
      "         0.0683,  0.0678], device='cuda:1', requires_grad=True)\n",
      "decoder_net_x.0.weight torch.Size([2631, 50]) torch.float32\n",
      "decoder_net_x.0.weight Parameter containing:\n",
      "tensor([[-0.0891,  0.0643,  0.0420,  ..., -0.1007,  0.0132, -0.0341],\n",
      "        [-0.0562,  0.0102, -0.0436,  ..., -0.0904,  0.0394,  0.1247],\n",
      "        [-0.1253,  0.0670,  0.1018,  ..., -0.0732, -0.1187,  0.1339],\n",
      "        ...,\n",
      "        [ 0.0363, -0.1018, -0.0302,  ...,  0.0336, -0.0292,  0.0663],\n",
      "        [-0.1332,  0.0264, -0.0324,  ...,  0.1207, -0.0753,  0.0233],\n",
      "        [-0.1156, -0.0955, -0.0839,  ...,  0.0243,  0.1045,  0.1017]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "decoder_net_x.0.bias torch.Size([2631]) torch.float32\n",
      "decoder_net_x.0.bias Parameter containing:\n",
      "tensor([-0.1107,  0.1283, -0.0964,  ..., -0.1336, -0.0020, -0.0576],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "decoder_net_y.0.weight torch.Size([182, 50]) torch.float32\n",
      "decoder_net_y.0.weight Parameter containing:\n",
      "tensor([[-0.0382, -0.0917,  0.0881,  ..., -0.0560, -0.1306,  0.1035],\n",
      "        [ 0.0411,  0.0990,  0.0990,  ...,  0.1095,  0.0807, -0.0282],\n",
      "        [ 0.0450,  0.1061,  0.0767,  ...,  0.0995,  0.1288,  0.1312],\n",
      "        ...,\n",
      "        [ 0.0025, -0.1188,  0.1280,  ..., -0.0162, -0.1019,  0.0833],\n",
      "        [ 0.1248,  0.0025, -0.0968,  ...,  0.0885, -0.0855, -0.0855],\n",
      "        [ 0.0167, -0.1312, -0.0327,  ..., -0.0676, -0.0497,  0.0201]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "decoder_net_y.0.bias torch.Size([182]) torch.float32\n",
      "decoder_net_y.0.bias Parameter containing:\n",
      "tensor([ 1.2831e-01, -1.2428e-01, -1.1309e-02,  9.9235e-02,  2.0311e-02,\n",
      "         2.2530e-02,  1.0770e-01,  9.4735e-02,  5.2987e-02,  4.7738e-02,\n",
      "        -8.0667e-02,  7.2742e-02,  7.4328e-02,  1.0022e-01, -1.0672e-01,\n",
      "        -8.0392e-02, -1.2835e-02, -3.9012e-02, -4.6282e-02,  1.1927e-01,\n",
      "         6.9624e-02,  1.2781e-01, -9.6152e-02, -3.7063e-02, -5.4043e-02,\n",
      "         8.8070e-03, -5.5857e-02, -2.5609e-02,  1.8050e-02,  2.1238e-02,\n",
      "         9.3956e-02, -1.2382e-01, -6.5530e-02,  8.6891e-02,  8.9241e-02,\n",
      "         1.6893e-02, -9.2492e-02,  1.2346e-01, -1.1296e-01,  6.2933e-02,\n",
      "         8.0003e-02, -4.0739e-02,  7.3302e-02,  1.2590e-01,  1.2093e-01,\n",
      "         6.3815e-02, -1.4025e-01, -6.3529e-02,  8.9399e-02,  7.4638e-02,\n",
      "         2.2681e-02, -1.0651e-01,  4.2608e-02,  3.8046e-02,  8.0013e-03,\n",
      "         6.3665e-02, -1.3313e-01, -2.2260e-02, -1.0079e-01, -6.6109e-02,\n",
      "        -1.7145e-02,  2.7519e-02,  6.7738e-02,  9.3680e-02, -7.7197e-02,\n",
      "         8.1322e-02, -3.8967e-02,  1.3459e-01, -2.9701e-02,  3.1121e-02,\n",
      "         6.6975e-02, -1.2197e-01, -7.6626e-03, -6.6224e-03,  1.2158e-01,\n",
      "         6.4257e-03,  4.5769e-03, -1.5962e-02, -1.2932e-01, -6.0950e-02,\n",
      "        -3.6757e-02,  4.9996e-03,  1.1333e-01,  6.3596e-02,  2.9162e-02,\n",
      "        -7.5590e-02,  9.2225e-02, -1.3765e-01,  2.1700e-02,  7.6286e-02,\n",
      "         7.9113e-02,  1.2567e-01,  9.7697e-02, -3.1661e-02,  9.0996e-02,\n",
      "         1.3808e-01, -4.5904e-02,  5.2183e-02,  1.3076e-01, -5.7306e-02,\n",
      "        -1.3017e-01,  6.1106e-04, -1.5833e-02, -8.5701e-02, -4.4265e-02,\n",
      "        -2.6230e-02,  1.1515e-01, -1.1546e-01,  5.9659e-02,  9.0658e-02,\n",
      "         5.3126e-02, -8.3252e-02, -1.3328e-01,  1.0447e-01, -1.3375e-02,\n",
      "        -1.2228e-01, -1.2953e-01,  7.4551e-02, -1.3435e-01,  6.7109e-03,\n",
      "         8.9424e-02,  1.0353e-04, -1.0915e-01,  1.3706e-01,  1.3942e-01,\n",
      "         4.0212e-02, -7.1684e-02, -1.0047e-01, -8.5666e-02, -5.0464e-02,\n",
      "         7.9910e-02,  7.3500e-02, -9.8045e-02,  5.7122e-02, -5.4379e-02,\n",
      "        -6.7773e-02, -1.2900e-01, -8.0355e-02,  8.8732e-02,  2.6438e-02,\n",
      "         9.3949e-02,  1.0163e-01, -2.7107e-02,  7.1544e-02,  6.3505e-02,\n",
      "         1.1206e-01, -4.4798e-02,  9.4916e-02,  7.1669e-02, -8.0102e-02,\n",
      "        -6.3671e-02,  8.4252e-03, -1.2108e-01,  9.4179e-02,  6.8977e-02,\n",
      "        -2.4574e-02,  1.0574e-02,  7.9831e-02, -9.2023e-02, -4.6603e-02,\n",
      "         2.9192e-02, -6.5256e-03, -5.1852e-02, -3.1552e-02, -3.7829e-02,\n",
      "        -5.6121e-02, -1.0097e-01, -6.8684e-02, -4.7432e-02, -1.8934e-03,\n",
      "         5.0390e-02, -1.7101e-02, -2.1415e-02, -4.0634e-02, -6.7100e-02,\n",
      "         1.3934e-01, -1.3612e-03, -1.0221e-01,  9.5642e-02,  2.6458e-02,\n",
      "        -1.8396e-02,  6.2317e-02], device='cuda:1', requires_grad=True)\n",
      "mu_zx0_net.0.weight torch.Size([50, 50]) torch.float32\n",
      "mu_zx0_net.0.weight Parameter containing:\n",
      "tensor([[-0.0294, -0.0258, -0.0442,  ..., -0.0798,  0.0098, -0.0362],\n",
      "        [-0.0274, -0.0465,  0.1230,  ..., -0.0791, -0.0383,  0.0231],\n",
      "        [-0.0767, -0.0854, -0.0235,  ..., -0.1008, -0.0484, -0.0049],\n",
      "        ...,\n",
      "        [-0.0043, -0.1207,  0.0961,  ..., -0.0211, -0.0173, -0.1033],\n",
      "        [ 0.0228,  0.0548, -0.1187,  ..., -0.1341,  0.0728,  0.0567],\n",
      "        [-0.0610,  0.0794,  0.0049,  ..., -0.0990, -0.0365,  0.0432]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "mu_zx0_net.0.bias torch.Size([50]) torch.float32\n",
      "mu_zx0_net.0.bias Parameter containing:\n",
      "tensor([-0.0586,  0.0289,  0.0734,  0.0613, -0.0456,  0.0413,  0.0638,  0.1193,\n",
      "         0.0737,  0.0651,  0.0663,  0.0449, -0.0492,  0.0675, -0.0859,  0.0161,\n",
      "        -0.1387, -0.0060,  0.0195,  0.0742, -0.1289, -0.0589,  0.0922,  0.0381,\n",
      "         0.0808, -0.0242, -0.0157,  0.0471,  0.0982,  0.0787, -0.0841,  0.0130,\n",
      "        -0.0039, -0.0105,  0.0010, -0.0508, -0.0989,  0.1267,  0.0343, -0.0007,\n",
      "         0.0581,  0.0064, -0.1019,  0.0702,  0.0376,  0.0543,  0.1100,  0.0808,\n",
      "        -0.0512, -0.0329], device='cuda:1', requires_grad=True)\n",
      "sigma_zx0_net.0.weight torch.Size([50, 50]) torch.float32\n",
      "sigma_zx0_net.0.weight Parameter containing:\n",
      "tensor([[-0.0267,  0.0823, -0.0093,  ..., -0.0873,  0.0659,  0.0927],\n",
      "        [-0.0695,  0.0119, -0.0118,  ..., -0.0492, -0.0902,  0.0953],\n",
      "        [-0.0369,  0.0238,  0.1300,  ...,  0.0417, -0.1141,  0.0452],\n",
      "        ...,\n",
      "        [-0.0693,  0.0286, -0.0386,  ..., -0.0585, -0.1316, -0.1380],\n",
      "        [-0.0386,  0.0364,  0.0010,  ..., -0.0034,  0.0419,  0.1379],\n",
      "        [-0.0556, -0.0556,  0.0079,  ..., -0.1372, -0.0570,  0.0337]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "sigma_zx0_net.0.bias torch.Size([50]) torch.float32\n",
      "sigma_zx0_net.0.bias Parameter containing:\n",
      "tensor([ 0.0664,  0.0648,  0.0817,  0.0959, -0.0107,  0.0013,  0.0285, -0.0353,\n",
      "        -0.0233,  0.1243, -0.0634,  0.0686,  0.0058,  0.1224, -0.1080,  0.0156,\n",
      "         0.1121,  0.0466,  0.0676,  0.1175, -0.1210,  0.0798,  0.0310, -0.0265,\n",
      "         0.0411,  0.0553, -0.0712,  0.0195,  0.1370,  0.0973,  0.0972,  0.1169,\n",
      "         0.0530, -0.0435,  0.1229, -0.0008,  0.0821,  0.0195,  0.0933, -0.0486,\n",
      "        -0.0169, -0.0294,  0.1079,  0.0048, -0.0385,  0.1327,  0.0951, -0.0865,\n",
      "        -0.0777, -0.1017], device='cuda:1', requires_grad=True)\n",
      "mu_zy0_net.0.weight torch.Size([50, 50]) torch.float32\n",
      "mu_zy0_net.0.weight Parameter containing:\n",
      "tensor([[-0.1240,  0.0888,  0.0892,  ...,  0.0008, -0.0062,  0.0519],\n",
      "        [-0.0729, -0.1162, -0.0264,  ..., -0.0642,  0.0896,  0.0127],\n",
      "        [ 0.1176,  0.0752, -0.0065,  ..., -0.0580,  0.1064, -0.0071],\n",
      "        ...,\n",
      "        [-0.0166, -0.0356,  0.0636,  ..., -0.0467,  0.0698,  0.0056],\n",
      "        [-0.0547, -0.0056, -0.1083,  ..., -0.0444, -0.1149, -0.0925],\n",
      "        [-0.0394,  0.0378, -0.1249,  ...,  0.0348,  0.0266, -0.1019]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "mu_zy0_net.0.bias torch.Size([50]) torch.float32\n",
      "mu_zy0_net.0.bias Parameter containing:\n",
      "tensor([-0.0844,  0.1299, -0.0703, -0.0917, -0.1404,  0.1397,  0.0086, -0.1301,\n",
      "        -0.0149,  0.1145, -0.0467,  0.0127,  0.0044, -0.1122, -0.1322,  0.1207,\n",
      "         0.0512,  0.1312,  0.0518, -0.0052,  0.0045, -0.0554, -0.0194, -0.0701,\n",
      "         0.0181,  0.1130,  0.0060, -0.0210,  0.0695, -0.0661, -0.0305,  0.0675,\n",
      "        -0.1085, -0.0209,  0.0876, -0.1296,  0.0298, -0.1019, -0.0590,  0.1297,\n",
      "         0.0534,  0.1170,  0.0729,  0.1187, -0.0011, -0.0347,  0.0462,  0.1074,\n",
      "        -0.0475,  0.1253], device='cuda:1', requires_grad=True)\n",
      "sigma_zy0_net.0.weight torch.Size([50, 50]) torch.float32\n",
      "sigma_zy0_net.0.weight Parameter containing:\n",
      "tensor([[ 0.0762, -0.0390, -0.0229,  ..., -0.1339,  0.0696, -0.0043],\n",
      "        [ 0.0158,  0.1272,  0.0933,  ..., -0.0216,  0.0183, -0.1024],\n",
      "        [-0.0944,  0.0036,  0.0541,  ...,  0.1158, -0.0908, -0.0139],\n",
      "        ...,\n",
      "        [-0.1317, -0.1087,  0.1137,  ..., -0.0601, -0.0814,  0.0710],\n",
      "        [ 0.1080,  0.0043, -0.0476,  ..., -0.1034,  0.0844,  0.1333],\n",
      "        [-0.0857, -0.0657, -0.0813,  ...,  0.0691, -0.1369, -0.0053]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "sigma_zy0_net.0.bias torch.Size([50]) torch.float32\n",
      "sigma_zy0_net.0.bias Parameter containing:\n",
      "tensor([-9.1433e-02,  5.6772e-03, -9.4279e-02,  3.6192e-02,  3.9228e-02,\n",
      "        -8.1784e-02, -2.8094e-02, -1.1013e-01,  4.9202e-02,  1.1020e-01,\n",
      "         1.0731e-01,  6.4843e-02,  1.8089e-05,  2.8646e-02,  1.8321e-02,\n",
      "         9.9342e-02, -1.0086e-01,  1.3868e-01, -1.2938e-01,  5.6055e-02,\n",
      "        -1.1468e-01, -7.3474e-02,  9.8427e-02,  1.1586e-01,  1.3654e-01,\n",
      "         1.7245e-02, -5.4166e-02, -9.6717e-02,  1.1833e-01, -1.2872e-01,\n",
      "         1.0634e-01,  6.0947e-02,  1.0711e-01, -1.4751e-03,  1.0256e-01,\n",
      "         6.6227e-02, -2.5587e-02, -6.3937e-02,  1.0238e-01, -6.9101e-02,\n",
      "        -7.4491e-02, -2.9002e-02, -4.1339e-02, -6.9768e-02,  1.0541e-01,\n",
      "         7.1031e-02,  4.3353e-02, -2.6373e-02,  1.1454e-01, -7.3697e-02],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "alpha_t_net.0.weight torch.Size([1, 100]) torch.float32\n",
      "alpha_t_net.0.weight Parameter containing:\n",
      "tensor([[-0.0921, -0.0241, -0.0465,  0.0526, -0.0620,  0.0507,  0.0246,  0.0722,\n",
      "         -0.0642,  0.0114, -0.0319,  0.0272,  0.0195,  0.0559, -0.0283, -0.0953,\n",
      "          0.0454,  0.0861,  0.0644, -0.0893, -0.0189, -0.0595, -0.0224,  0.0468,\n",
      "         -0.0542, -0.0162,  0.0985,  0.0825, -0.0303, -0.0131, -0.0623,  0.0386,\n",
      "         -0.0602, -0.0627,  0.0289,  0.0258,  0.0398,  0.0231, -0.0816,  0.0576,\n",
      "         -0.0922, -0.0121,  0.0937,  0.0402, -0.0565, -0.0751,  0.0372, -0.0015,\n",
      "          0.0523, -0.0887, -0.0632,  0.0608,  0.0876,  0.0862,  0.0259, -0.0072,\n",
      "          0.0668, -0.0831,  0.0410, -0.0133,  0.0534, -0.0973,  0.0107,  0.0743,\n",
      "         -0.0086, -0.0526, -0.0604, -0.0869, -0.0960,  0.0556, -0.0154,  0.0577,\n",
      "          0.0432,  0.0552,  0.0696, -0.0371,  0.0142,  0.0572,  0.0540,  0.0424,\n",
      "         -0.0320,  0.0717, -0.0466, -0.0847,  0.0693,  0.0776,  0.0839, -0.0334,\n",
      "         -0.0537, -0.0728, -0.0489, -0.0626,  0.0603,  0.0733,  0.0433,  0.0165,\n",
      "          0.0985, -0.0555,  0.0611,  0.0168]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "alpha_t_net.0.bias torch.Size([1]) torch.float32\n",
      "alpha_t_net.0.bias Parameter containing:\n",
      "tensor([0.0657], device='cuda:1', requires_grad=True)\n",
      "beta_t_net.0.weight torch.Size([1, 100]) torch.float32\n",
      "beta_t_net.0.weight Parameter containing:\n",
      "tensor([[ 0.0643, -0.0153, -0.0887,  0.0929,  0.0696,  0.0396, -0.0918,  0.0688,\n",
      "          0.0338,  0.0434,  0.0933, -0.0629,  0.0653, -0.0284, -0.0954,  0.0831,\n",
      "         -0.0968, -0.0664,  0.0457,  0.0616,  0.0531,  0.0122, -0.0421,  0.0720,\n",
      "          0.0574,  0.0676,  0.0388, -0.0346,  0.0534, -0.0700,  0.0608, -0.0504,\n",
      "          0.0745, -0.0838, -0.0997,  0.0653, -0.0611,  0.0312, -0.0572, -0.0331,\n",
      "          0.0444, -0.0013,  0.0865, -0.0390, -0.0489, -0.0927,  0.0275,  0.0430,\n",
      "          0.0220,  0.0315,  0.0102,  0.0317,  0.0855,  0.0758,  0.0168, -0.0277,\n",
      "          0.0274,  0.0733,  0.0065,  0.0617,  0.0985, -0.0169,  0.0213,  0.0377,\n",
      "          0.0457,  0.0667, -0.0948, -0.0877,  0.0763,  0.0557, -0.0660, -0.0030,\n",
      "          0.0548,  0.0518,  0.0312, -0.0513,  0.0214, -0.0006, -0.0508,  0.0806,\n",
      "         -0.0421,  0.0046,  0.0880,  0.0346,  0.0117,  0.0251,  0.0566, -0.0151,\n",
      "          0.0023,  0.0831, -0.0953,  0.0040,  0.0019,  0.0720, -0.0567, -0.0132,\n",
      "          0.0528, -0.0908,  0.0681,  0.0702]], device='cuda:1',\n",
      "       requires_grad=True)\n",
      "beta_t_net.0.bias torch.Size([1]) torch.float32\n",
      "beta_t_net.0.bias Parameter containing:\n",
      "tensor([-0.0885], device='cuda:1', requires_grad=True)\n",
      "node_func.fzx.0.weight torch.Size([200, 100]) torch.float32\n",
      "node_func.fzx.0.weight Parameter containing:\n",
      "tensor([[ 0.0001,  0.0060, -0.0116,  ..., -0.0167, -0.0047, -0.0245],\n",
      "        [ 0.0043, -0.0062,  0.0016,  ..., -0.0237,  0.0088, -0.0059],\n",
      "        [ 0.0206,  0.0039, -0.0123,  ...,  0.0035,  0.0199, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0043, -0.0084,  0.0051,  ..., -0.0036,  0.0014,  0.0157],\n",
      "        [-0.0085, -0.0217,  0.0004,  ...,  0.0227, -0.0093,  0.0031],\n",
      "        [ 0.0045, -0.0009, -0.0022,  ...,  0.0122,  0.0057,  0.0003]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "node_func.fzx.0.bias torch.Size([200]) torch.float32\n",
      "node_func.fzx.0.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1', requires_grad=True)\n",
      "node_func.fzx.2.weight torch.Size([50, 200]) torch.float32\n",
      "node_func.fzx.2.weight Parameter containing:\n",
      "tensor([[-1.1319e-02, -8.1431e-03,  3.8145e-04,  ...,  7.3059e-03,\n",
      "          1.9054e-03,  1.3972e-03],\n",
      "        [-1.3379e-03, -1.4049e-02, -1.2546e-03,  ...,  6.7390e-03,\n",
      "         -6.7970e-03,  2.5716e-03],\n",
      "        [ 2.0104e-02,  8.6310e-03,  3.6637e-03,  ...,  1.1110e-02,\n",
      "          1.5927e-02,  1.1431e-02],\n",
      "        ...,\n",
      "        [ 3.7599e-03, -4.1041e-03, -4.0522e-03,  ...,  3.5556e-03,\n",
      "         -7.1759e-03,  4.6784e-03],\n",
      "        [-8.3389e-05, -4.2062e-03,  2.2438e-04,  ..., -4.4922e-04,\n",
      "         -1.1743e-02, -9.4336e-03],\n",
      "        [-1.1231e-02,  1.9732e-02, -3.0314e-03,  ...,  1.3162e-02,\n",
      "         -9.9275e-04,  1.3052e-02]], device='cuda:1', requires_grad=True)\n",
      "node_func.fzx.2.bias torch.Size([50]) torch.float32\n",
      "node_func.fzx.2.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:1', requires_grad=True)\n",
      "node_func.fzy.0.weight torch.Size([200, 100]) torch.float32\n",
      "node_func.fzy.0.weight Parameter containing:\n",
      "tensor([[ 0.0117, -0.0236,  0.0014,  ..., -0.0015, -0.0137, -0.0030],\n",
      "        [-0.0131,  0.0015, -0.0004,  ..., -0.0060,  0.0031,  0.0014],\n",
      "        [ 0.0021,  0.0126, -0.0022,  ..., -0.0064,  0.0008,  0.0159],\n",
      "        ...,\n",
      "        [-0.0164,  0.0053, -0.0103,  ...,  0.0004,  0.0060, -0.0103],\n",
      "        [-0.0084,  0.0023,  0.0050,  ..., -0.0153,  0.0003, -0.0110],\n",
      "        [-0.0128,  0.0045, -0.0027,  ...,  0.0047, -0.0125, -0.0112]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "node_func.fzy.0.bias torch.Size([200]) torch.float32\n",
      "node_func.fzy.0.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:1', requires_grad=True)\n",
      "node_func.fzy.2.weight torch.Size([50, 200]) torch.float32\n",
      "node_func.fzy.2.weight Parameter containing:\n",
      "tensor([[-0.0016,  0.0075,  0.0101,  ..., -0.0079, -0.0179, -0.0062],\n",
      "        [ 0.0032, -0.0058, -0.0063,  ..., -0.0027,  0.0234,  0.0071],\n",
      "        [-0.0041,  0.0022, -0.0150,  ..., -0.0099, -0.0055, -0.0018],\n",
      "        ...,\n",
      "        [-0.0134,  0.0064, -0.0114,  ...,  0.0154,  0.0060, -0.0005],\n",
      "        [ 0.0021,  0.0156, -0.0009,  ...,  0.0073, -0.0014, -0.0054],\n",
      "        [-0.0159,  0.0267, -0.0069,  ...,  0.0068, -0.0099, -0.0048]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "node_func.fzy.2.bias torch.Size([50]) torch.float32\n",
      "node_func.fzy.2.bias Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:1', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = DynaVelo(x_dim=adata_rna.shape[1], y_dim=adata_atac.shape[1], device=device, dataset_name=dataset_name, sample_name=sample_name).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
    "print('number of parameters func: ', n_params)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape, param.dtype)\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\tloss_train\tloss_test\tnll_x\tnll_y\tloss_vel\tloss_con\tkl_z0\tkl_t\n",
      "1\t50664.1216\t43762.0564\t38073.427\t5426.6752\t-0.3858\t0.0104\t4.0081\t0.0073\n",
      "2\t39440.9824\t35187.485\t32190.6065\t4597.216\t-0.5479\t0.0061\t3.8126\t0.0057\n",
      "3\t32725.2636\t30225.7602\t27655.5584\t3921.3342\t-0.5982\t0.0075\t4.5524\t0.0032\n",
      "4\t28512.1097\t27026.3698\t25624.995\t3329.9868\t-0.6298\t0.0044\t4.3227\t0.0027\n",
      "5\t25812.5805\t24687.3325\t24319.5096\t2930.1483\t-0.6544\t0.0044\t3.9356\t0.0022\n",
      "6\t23896.739\t23108.1465\t23309.7959\t2654.1318\t-0.6786\t0.0043\t3.8849\t0.0019\n",
      "7\t22456.162\t21742.8543\t22247.257\t2489.9742\t-0.6952\t0.0048\t3.9084\t0.0018\n",
      "8\t21373.6883\t20760.8313\t21358.9242\t2509.9053\t-0.7032\t0.0029\t3.8926\t0.0023\n",
      "9\t20284.6537\t19973.5837\t20992.2283\t2361.5884\t-0.7156\t0.0023\t3.7473\t0.0056\n",
      "10\t19595.7893\t19067.0815\t20794.8586\t2044.6135\t-0.7355\t0.0052\t3.5198\t0.0108\n",
      "11\t18832.7779\t18195.4052\t20192.1587\t1907.1738\t-0.7428\t0.0064\t3.4274\t0.0324\n",
      "12\t18456.561\t18059.4926\t19898.9275\t1933.7117\t-0.7582\t0.0027\t3.7336\t0.0479\n",
      "13\t17886.7823\t17610.4466\t19933.9981\t1745.8582\t-0.7601\t0.0071\t3.3748\t0.0858\n",
      "14\t17535.6313\t17678.9265\t19942.5953\t1736.5912\t-0.7715\t0.0147\t3.4692\t0.0979\n",
      "INFO: Early stopping counter 1 of 10\n",
      "15\t17188.3686\t17040.8397\t19719.179\t1625.0632\t-0.7782\t0.006\t3.3117\t0.1065\n",
      "16\t16824.9849\t16643.4509\t19715.0682\t1628.3038\t-0.7859\t0.0066\t2.9846\t0.1085\n",
      "17\t16578.313\t16314.285\t19332.1303\t1657.8194\t-0.785\t0.0103\t2.9415\t0.1293\n",
      "18\t16312.2553\t16292.7208\t19557.6427\t1532.8932\t-0.8015\t0.0053\t3.0253\t0.1395\n",
      "19\t16056.0937\t15986.1037\t19068.8285\t1606.2868\t-0.7874\t0.0035\t3.0067\t0.144\n",
      "20\t15972.3646\t15729.3003\t18989.5509\t1531.6923\t-0.7916\t0.0029\t2.9484\t0.1469\n",
      "21\t15719.7196\t15470.367\t18919.6264\t1452.3149\t-0.8059\t0.0023\t2.9951\t0.139\n",
      "22\t15558.8091\t15451.7164\t18941.0529\t1503.3334\t-0.8068\t0.002\t2.8878\t0.168\n",
      "23\t15370.474\t15220.0005\t18836.4751\t1413.2953\t-0.81\t0.0026\t2.88\t0.1639\n",
      "24\t15169.1523\t15161.8197\t18925.6626\t1447.8121\t-0.8065\t0.0033\t2.6674\t0.1534\n",
      "25\t15101.6705\t14921.5233\t18582.191\t1395.7545\t-0.8032\t0.0019\t2.7964\t0.1607\n",
      "26\t14931.9954\t14877.1143\t18590.7624\t1419.0519\t-0.809\t0.002\t2.7636\t0.174\n",
      "27\t14710.5128\t14723.0674\t18550.0578\t1471.39\t-0.7985\t0.0029\t2.4928\t0.1654\n",
      "28\t14595.9821\t14530.6385\t18527.1023\t1424.6525\t-0.8114\t0.0025\t2.5106\t0.1574\n",
      "29\t14507.7699\t14533.962\t18328.8281\t1401.5288\t-0.7986\t0.0096\t2.5226\t0.1709\n",
      "INFO: Early stopping counter 1 of 10\n",
      "30\t14393.2266\t14693.4485\t18533.7919\t1469.7086\t-0.7904\t0.0035\t2.3638\t0.1952\n",
      "INFO: Early stopping counter 2 of 10\n",
      "31\t14317.0209\t14446.379\t18400.1723\t1395.3701\t-0.8007\t0.0019\t2.4599\t0.1788\n",
      "32\t14183.5684\t14381.6644\t18339.0365\t1528.7245\t-0.7923\t0.0017\t2.2422\t0.1776\n",
      "33\t14037.5138\t14239.3873\t18389.1338\t1433.9186\t-0.7905\t0.0027\t2.1165\t0.1774\n",
      "34\t14026.7426\t13893.8893\t17950.2382\t1440.3827\t-0.7988\t0.0016\t2.283\t0.1922\n",
      "35\t13930.3262\t13902.9492\t17883.6116\t1375.6489\t-0.7938\t0.0033\t2.3577\t0.1912\n",
      "INFO: Early stopping counter 1 of 10\n",
      "36\t13819.7494\t13790.1574\t18032.5946\t1346.0016\t-0.7975\t0.002\t2.1496\t0.2164\n",
      "37\t13752.5017\t13927.1086\t18075.791\t1452.1074\t-0.794\t0.0014\t2.1263\t0.1992\n",
      "INFO: Early stopping counter 1 of 10\n",
      "38\t13550.9574\t13374.2365\t17609.9428\t1388.1565\t-0.7977\t0.0024\t2.1132\t0.2163\n",
      "39\t13549.5787\t13587.354\t17843.1342\t1341.8608\t-0.7876\t0.002\t2.0421\t0.2168\n",
      "INFO: Early stopping counter 1 of 10\n",
      "40\t13403.1287\t13314.3634\t17521.8227\t1419.5151\t-0.7899\t0.0022\t2.0072\t0.2429\n",
      "41\t13340.7654\t13403.9354\t17623.7296\t1389.5738\t-0.7825\t0.0026\t1.9369\t0.2526\n",
      "INFO: Early stopping counter 1 of 10\n",
      "42\t13149.3904\t13197.8422\t17504.0958\t1378.505\t-0.7873\t0.0024\t1.8833\t0.28\n",
      "43\t12998.68\t13136.4955\t17377.9643\t1392.0946\t-0.7727\t0.0023\t1.7509\t0.3195\n",
      "44\t12813.7849\t12719.0305\t17157.0521\t1348.0083\t-0.787\t0.0032\t1.6876\t0.3649\n",
      "45\t12571.3146\t12491.0817\t16929.0006\t1366.3883\t-0.776\t0.0038\t1.5176\t0.3996\n",
      "46\t12399.6182\t12380.6735\t16875.3366\t1392.2086\t-0.7817\t0.0039\t1.4538\t0.438\n",
      "47\t12087.8571\t12028.4783\t16722.5445\t1295.1268\t-0.7846\t0.0037\t1.3765\t0.4428\n",
      "Repetitive time\n",
      "48\t11779.8528\t11779.9569\t16639.9191\t1355.0694\t-0.7987\t0.004\t1.2809\t0.4509\n",
      "49\t11669.7053\t11680.0613\t16550.6468\t1358.7695\t-0.8065\t0.0031\t1.3174\t0.4877\n",
      "50\t11517.437\t11279.2137\t16338.7268\t1327.9257\t-0.8206\t0.0028\t1.2966\t0.4944\n",
      "51\t11344.7913\t11138.4527\t16306.9967\t1289.7009\t-0.825\t0.0036\t1.2903\t0.4651\n",
      "52\t11229.0765\t11195.4459\t16279.6014\t1321.9189\t-0.8136\t0.0032\t1.2318\t0.4661\n",
      "INFO: Early stopping counter 1 of 10\n",
      "53\t11109.2459\t11211.1897\t16259.6535\t1350.8832\t-0.8128\t0.0033\t1.2367\t0.4591\n",
      "INFO: Early stopping counter 2 of 10\n",
      "54\t10975.3521\t11115.6555\t16211.3921\t1345.3198\t-0.8185\t0.0044\t1.2402\t0.4601\n",
      "55\t10966.9049\t10931.3599\t16201.7338\t1253.4074\t-0.8233\t0.0032\t1.2221\t0.4552\n",
      "56\t10881.6177\t10945.2197\t16143.5322\t1300.7931\t-0.824\t0.003\t1.2508\t0.4595\n",
      "INFO: Early stopping counter 1 of 10\n",
      "Repetitive time\n",
      "57\t10843.7018\t10867.1945\t16151.3587\t1219.8374\t-0.8216\t0.0044\t1.2182\t0.4495\n",
      "58\t10788.3204\t10840.0263\t16085.7687\t1252.1877\t-0.8266\t0.0024\t1.2872\t0.4571\n",
      "59\t10710.7688\t10872.2808\t16072.4037\t1283.5937\t-0.8243\t0.0025\t1.292\t0.4425\n",
      "INFO: Early stopping counter 1 of 10\n",
      "60\t10653.1703\t10800.2819\t16118.0128\t1240.1266\t-0.8273\t0.0027\t1.2459\t0.4423\n",
      "61\t10632.7512\t10649.8872\t16030.1623\t1205.1152\t-0.8336\t0.0026\t1.2776\t0.446\n",
      "62\t10533.4764\t10600.1349\t16055.8607\t1164.8723\t-0.8366\t0.0022\t1.256\t0.4678\n",
      "63\t10500.2864\t10763.6666\t16073.9119\t1187.7633\t-0.8208\t0.0042\t1.2285\t0.4398\n",
      "INFO: Early stopping counter 1 of 10\n",
      "64\t10547.1176\t10762.3096\t16075.2284\t1292.1697\t-0.8306\t0.0022\t1.2289\t0.4501\n",
      "INFO: Early stopping counter 2 of 10\n",
      "65\t10537.3803\t10599.3665\t15980.638\t1182.5367\t-0.8344\t0.0031\t1.2947\t0.455\n",
      "66\t10449.0541\t10651.6302\t16025.5368\t1231.5896\t-0.8297\t0.0034\t1.2102\t0.4469\n",
      "INFO: Early stopping counter 1 of 10\n",
      "67\t10439.1853\t10413.1676\t15971.3953\t1130.7433\t-0.8363\t0.0038\t1.2135\t0.4225\n",
      "68\t10383.6876\t10449.4844\t15970.2763\t1155.7213\t-0.8387\t0.0042\t1.2392\t0.4295\n",
      "INFO: Early stopping counter 1 of 10\n",
      "69\t10409.0827\t10369.5873\t15974.9574\t1128.0874\t-0.8366\t0.0019\t1.1735\t0.4401\n",
      "70\t10335.0391\t10558.3177\t15964.6336\t1158.3367\t-0.8284\t0.0074\t1.2205\t0.4249\n",
      "INFO: Early stopping counter 1 of 10\n",
      "71\t10323.3926\t10506.5001\t15934.2157\t1159.8259\t-0.8275\t0.0045\t1.2193\t0.4237\n",
      "INFO: Early stopping counter 2 of 10\n",
      "72\t10303.7063\t10627.6925\t16048.5248\t1312.3462\t-0.8314\t0.0023\t1.1253\t0.4333\n",
      "INFO: Early stopping counter 3 of 10\n",
      "73\t10288.5899\t10482.3424\t15976.1392\t1134.3791\t-0.8333\t0.003\t1.2261\t0.4493\n",
      "INFO: Early stopping counter 4 of 10\n",
      "74\t10228.2628\t10369.9821\t16005.7839\t1114.5769\t-0.8378\t0.0036\t1.1553\t0.4366\n",
      "INFO: Early stopping counter 5 of 10\n",
      "75\t10206.4678\t10461.0632\t15937.0333\t1188.896\t-0.8312\t0.0045\t1.1653\t0.4366\n",
      "Epoch 00075: reducing learning rate of group 0 to 5.0000e-04.\n",
      "INFO: Early stopping counter 6 of 10\n",
      "Repetitive time\n",
      "76\t10166.3479\t10300.0843\t15880.7509\t1188.7815\t-0.8392\t0.0044\t1.1653\t0.4128\n",
      "77\t10094.6079\t10365.6052\t15908.2676\t1115.0027\t-0.8357\t0.0042\t1.2282\t0.4294\n",
      "INFO: Early stopping counter 1 of 10\n",
      "78\t10092.0958\t10205.5682\t15882.3508\t1116.4622\t-0.8378\t0.0027\t1.1451\t0.4134\n",
      "Repetitive time\n",
      "79\t10073.2054\t10262.4768\t15819.3517\t1160.9337\t-0.8388\t0.0024\t1.2142\t0.4317\n",
      "INFO: Early stopping counter 1 of 10\n",
      "80\t10059.3013\t10228.1572\t15881.454\t1112.9484\t-0.843\t0.0024\t1.217\t0.4232\n",
      "INFO: Early stopping counter 2 of 10\n",
      "81\t10080.8811\t10314.1473\t15885.6046\t1153.7159\t-0.8365\t0.0039\t1.1704\t0.4306\n",
      "INFO: Early stopping counter 3 of 10\n",
      "82\t10042.0551\t10263.1644\t15873.8603\t1131.4382\t-0.838\t0.0026\t1.1961\t0.416\n",
      "INFO: Early stopping counter 4 of 10\n",
      "83\t10073.177\t10234.7238\t15860.4695\t1103.8397\t-0.8384\t0.0022\t1.1927\t0.4394\n",
      "INFO: Early stopping counter 5 of 10\n",
      "84\t10032.8981\t10229.4722\t15884.1596\t1107.5781\t-0.8427\t0.0022\t1.2152\t0.4283\n",
      "Epoch 00084: reducing learning rate of group 0 to 2.5000e-04.\n",
      "INFO: Early stopping counter 6 of 10\n",
      "85\t10008.7216\t10067.8453\t15846.0906\t1089.4114\t-0.8543\t0.0021\t1.2223\t0.4315\n",
      "86\t9954.7045\t10194.2857\t15860.7504\t1108.1261\t-0.8399\t0.0039\t1.1704\t0.4151\n",
      "INFO: Early stopping counter 1 of 10\n",
      "87\t10001.9299\t10335.2652\t15866.179\t1089.855\t-0.8351\t0.0087\t1.2188\t0.4241\n",
      "INFO: Early stopping counter 2 of 10\n",
      "88\t9983.0234\t10078.7185\t15868.9067\t1077.2293\t-0.8503\t0.0021\t1.1858\t0.4293\n",
      "INFO: Early stopping counter 3 of 10\n",
      "89\t9976.3445\t10234.27\t15864.9526\t1106.3236\t-0.8385\t0.002\t1.2056\t0.4226\n",
      "INFO: Early stopping counter 4 of 10\n",
      "90\t9919.1189\t10054.5831\t15800.2401\t1098.6725\t-0.846\t0.0021\t1.1757\t0.4181\n",
      "91\t9943.514\t10267.6611\t15846.2386\t1150.129\t-0.8383\t0.0027\t1.2066\t0.4209\n",
      "INFO: Early stopping counter 1 of 10\n",
      "92\t9993.836\t10057.549\t15808.9699\t1077.3492\t-0.8446\t0.0014\t1.1757\t0.4281\n",
      "INFO: Early stopping counter 2 of 10\n",
      "93\t9907.7709\t10159.3143\t15840.3451\t1167.9312\t-0.8452\t0.0016\t1.1755\t0.4119\n",
      "INFO: Early stopping counter 3 of 10\n",
      "94\t9898.4845\t10154.6152\t15841.6515\t1117.092\t-0.8427\t0.0035\t1.1831\t0.4043\n",
      "INFO: Early stopping counter 4 of 10\n",
      "95\t9882.445\t10028.9463\t15811.0864\t1110.2349\t-0.8499\t0.0017\t1.1746\t0.4149\n",
      "96\t9891.549\t10166.1926\t15830.42\t1098.475\t-0.84\t0.0054\t1.1626\t0.4211\n",
      "INFO: Early stopping counter 1 of 10\n",
      "97\t9907.8602\t10170.9013\t15851.0757\t1081.8141\t-0.8381\t0.0035\t1.1635\t0.4204\n",
      "INFO: Early stopping counter 2 of 10\n",
      "98\t9933.9771\t10050.9502\t15798.6151\t1067.8337\t-0.8439\t0.0015\t1.1876\t0.4218\n",
      "INFO: Early stopping counter 3 of 10\n",
      "99\t9868.5314\t10154.2408\t15808.2583\t1130.6099\t-0.8402\t0.0027\t1.1696\t0.4208\n",
      "INFO: Early stopping counter 4 of 10\n",
      "100\t9912.6489\t10124.3389\t15832.2809\t1076.3459\t-0.8431\t0.0024\t1.2031\t0.4204\n",
      "INFO: Early stopping counter 5 of 10\n",
      "101\t9899.9504\t10039.7165\t15797.1532\t1047.2584\t-0.8481\t0.0029\t1.2195\t0.4275\n",
      "Epoch 00101: reducing learning rate of group 0 to 1.2500e-04.\n",
      "INFO: Early stopping counter 6 of 10\n",
      "102\t9843.958\t10198.3864\t15819.2486\t1151.5517\t-0.8397\t0.0043\t1.1621\t0.4191\n",
      "INFO: Early stopping counter 7 of 10\n",
      "103\t9853.744\t10017.6163\t15828.3282\t1103.616\t-0.8516\t0.0016\t1.1671\t0.4193\n",
      "104\t9836.6085\t10012.826\t15803.1502\t1089.404\t-0.8529\t0.0021\t1.2037\t0.424\n",
      "105\t9829.1839\t10033.8206\t15803.9171\t1059.2948\t-0.8456\t0.0029\t1.1808\t0.4165\n",
      "INFO: Early stopping counter 1 of 10\n",
      "106\t9869.7291\t10108.3175\t15814.777\t1126.5604\t-0.8462\t0.002\t1.1875\t0.4216\n",
      "INFO: Early stopping counter 2 of 10\n",
      "107\t9820.9212\t10061.124\t15793.4038\t1122.0288\t-0.8495\t0.003\t1.1912\t0.4194\n",
      "INFO: Early stopping counter 3 of 10\n",
      "108\t9836.8712\t10086.971\t15839.5121\t1072.4231\t-0.8452\t0.0029\t1.1706\t0.4276\n",
      "INFO: Early stopping counter 4 of 10\n",
      "109\t9830.1277\t10109.131\t15814.3739\t1117.9924\t-0.8428\t0.002\t1.1611\t0.4243\n",
      "INFO: Early stopping counter 5 of 10\n",
      "110\t9840.9346\t10057.5871\t15815.7324\t1088.4683\t-0.847\t0.0029\t1.1711\t0.4232\n",
      "Epoch 00110: reducing learning rate of group 0 to 6.2500e-05.\n",
      "INFO: Early stopping counter 6 of 10\n",
      "111\t9801.8208\t10002.908\t15807.9785\t1098.0403\t-0.8511\t0.0021\t1.1682\t0.419\n",
      "112\t9828.7399\t9973.2065\t15814.7672\t1057.1397\t-0.8504\t0.0025\t1.1597\t0.4215\n",
      "113\t9847.1816\t10089.7564\t15825.2205\t1074.889\t-0.843\t0.0027\t1.1759\t0.416\n",
      "INFO: Early stopping counter 1 of 10\n",
      "114\t9806.202\t10125.4311\t15829.8313\t1075.3726\t-0.8401\t0.0032\t1.1662\t0.4223\n",
      "INFO: Early stopping counter 2 of 10\n",
      "115\t9839.7517\t10170.1652\t15853.8792\t1131.9028\t-0.8417\t0.0025\t1.1595\t0.4172\n",
      "INFO: Early stopping counter 3 of 10\n",
      "116\t9805.582\t10052.0675\t15812.4719\t1127.1252\t-0.8495\t0.0016\t1.172\t0.4196\n",
      "INFO: Early stopping counter 4 of 10\n",
      "117\t9821.5447\t10012.2111\t15819.5792\t1057.9836\t-0.8483\t0.003\t1.166\t0.4218\n",
      "INFO: Early stopping counter 5 of 10\n",
      "118\t9835.0052\t10019.7589\t15796.9389\t1058.1506\t-0.8479\t0.0033\t1.1849\t0.4252\n",
      "Epoch 00118: reducing learning rate of group 0 to 3.1250e-05.\n",
      "INFO: Early stopping counter 6 of 10\n",
      "119\t9839.6124\t10062.4959\t15804.1727\t1093.0931\t-0.8481\t0.0026\t1.1955\t0.4252\n",
      "INFO: Early stopping counter 7 of 10\n",
      "120\t9821.1999\t10077.1911\t15811.8346\t1103.7221\t-0.8487\t0.0043\t1.1853\t0.4208\n",
      "INFO: Early stopping counter 8 of 10\n",
      "121\t9804.1635\t10156.8487\t15806.6377\t1117.6779\t-0.8397\t0.0019\t1.1854\t0.4248\n",
      "INFO: Early stopping counter 9 of 10\n",
      "122\t9778.5691\t9988.0332\t15770.9659\t1044.069\t-0.8457\t0.003\t1.1766\t0.423\n",
      "INFO: Early stopping counter 10 of 10\n",
      "INFO: Early stopping\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model.fit(dataloader_train, dataloader_test, optimizer, max_epoch=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ckpt from ../checkpoints/Ben/Icn2Het-2/Ben_Icn2Het-2_DynaVelo_num_hidden_200_zxdim_50_zydim_50_k_z0_1000_k_t_1000_k_velocity_10000_k_consistency_10000_seed_0.pth\n"
     ]
    }
   ],
   "source": [
    "model.load(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting velocities and latent times\n",
    "After a DynaVelo model is trained, we use it to predict the latent times, RNA velocities, and motif velocities for all cells, saving the results in the adata files. The mode evaluation-sample means that we sample from the learned posterior probabilities of initial points in the latent space and latent times of cells `n_samples` times, then report the mean and variance of the predicted velocities. The variance can represent uncertainty in the velocities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n:  0\n",
      "n:  1\n",
      "n:  2\n",
      "n:  3\n",
      "n:  4\n",
      "n:  5\n",
      "n:  6\n",
      "n:  7\n",
      "n:  8\n",
      "n:  9\n",
      "n:  10\n",
      "n:  11\n",
      "n:  12\n",
      "n:  13\n",
      "n:  14\n",
      "n:  15\n",
      "n:  16\n",
      "n:  17\n",
      "n:  18\n",
      "n:  19\n",
      "n:  20\n",
      "n:  21\n",
      "n:  22\n",
      "Repetitive time\n",
      "n:  23\n",
      "n:  24\n",
      "n:  25\n",
      "Repetitive time\n",
      "Repetitive time\n",
      "n:  26\n",
      "n:  27\n",
      "n:  28\n",
      "n:  29\n",
      "n:  30\n",
      "n:  31\n",
      "n:  32\n",
      "n:  33\n",
      "n:  34\n",
      "n:  35\n",
      "n:  36\n",
      "n:  37\n",
      "n:  38\n",
      "n:  39\n",
      "n:  40\n",
      "Repetitive time\n",
      "n:  41\n",
      "n:  42\n",
      "n:  43\n",
      "n:  44\n",
      "n:  45\n",
      "n:  46\n",
      "n:  47\n",
      "n:  48\n",
      "n:  49\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "model.mode = 'evaluation-sample'\n",
    "adata_rna_pred, adata_atac_pred = model.evaluate(adata_rna, adata_atac, dataloader, n_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Jacobian matrices\n",
    "To learn dynamic and cell-state-specific gene regulatory networks (GRNs), we calculate the Jacobian matrices of the trained DynaVelo model. There are four types of Jacobian matrices:\n",
    "\n",
    "(1) J_vx_x, which measures the partial effects of RNA expression on RNA velocity and has the shape [n_cells, n_genes, n_genes].<br> \n",
    "(2) J_vy_x, which measures the partial effects of RNA expression on motif velocity and has the shape [n_cells, n_tfs, n_genes].<br> \n",
    "(3) J_vx_y, which measures the partial effects of TF motif accessibility on RNA velocity and has the shape [n_cells, n_genes, n_tfs].<br> \n",
    "(4) J_vy_y, which measures the partial effects of TF motif accessibility on motif velocity and has the shape [n_cells, n_tfs, n_tfs].\n",
    "\n",
    "Since the Jacobians are 3D dense tensors, they take a lot of memory, so we choose a subset of genes we are interested in and calculate the Jacobians for them. We include all the TFs in the subset of `genes_of_interest`, as we are interested in understanding how TFs regulate each other. The mode evaluation-fixed means that we use the mean of the latent times and initial points of the cells in the latent space without sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "['Ahr', 'Arid3a', 'Arid3b', 'Arid5a', 'Arnt', 'Arntl', 'Atf1', 'Atf2', 'Atf4', 'Atf7', 'Bach1', 'Bach2', 'Batf', 'Bcl6', 'Bhlhe40', 'Bhlhe41', 'Cebpg', 'Clock', 'Creb1', 'Creb3', 'Creb3l2', 'Crem', 'Ctcf', 'Cux1', 'E2f1', 'E2f2', 'E2f3', 'E2f4', 'E2f5', 'E2f7', 'E2f8', 'Ebf1', 'Egr2', 'Egr3', 'Elf1', 'Elf2', 'Elf4', 'Elk3', 'Elk4', 'Esr1', 'Esrra', 'Ets1', 'Etv3', 'Etv6', 'Fli1', 'Fos', 'Fosb', 'Foxj2', 'Foxj3', 'Foxk1', 'Foxk2', 'Foxo1', 'Foxo3', 'Foxp1', 'Gabpa', 'Gfi1', 'Gmeb1', 'Gmeb2', 'Grhl1', 'Hes1', 'Hif1a', 'Hinfp', 'Hltf', 'Hmbox1', 'Hsf1', 'Id2', 'Ikzf1', 'Irf1', 'Irf2', 'Irf3', 'Irf4', 'Irf5', 'Irf8', 'Irf9', 'Junb', 'Klf12', 'Klf13', 'Klf3', 'Klf4', 'Klf6', 'Klf8', 'Lef1', 'Lin54', 'Lyl1', 'Max', 'Maz', 'Mbd2', 'Mecp2', 'Mef2a', 'Mef2b', 'Mef2c', 'Mef2d', 'Mga', 'Mlxip', 'Mnt', 'Mtf1', 'Mxi1', 'Myb', 'Mybl1', 'Mybl2', 'Myc', 'Nfat5', 'Nfatc1', 'Nfatc2', 'Nfatc3', 'Nfe2l2', 'Nfia', 'Nfic', 'Nfkb1', 'Nfkb2', 'Nfya', 'Nfyb', 'Nfyc', 'Notch2', 'Nr1d2', 'Nr2c1', 'Nr2c2', 'Nr2f6', 'Nr3c1', 'Nr3c2', 'Nr4a1', 'Nr6a1', 'Nrf1', 'Patz1', 'Pax5', 'Pbx2', 'Pbx3', 'Pknox1', 'Pou2f1', 'Pou2f2', 'Pou6f1', 'Prdm1', 'Prdm4', 'Rara', 'Rbpj', 'Rel', 'Rela', 'Relb', 'Rest', 'Rfx3', 'Rfx5', 'Rreb1', 'Runx1', 'Runx3', 'Smad2', 'Smad3', 'Smad4', 'Sox5', 'Sp1', 'Sp2', 'Sp3', 'Sp4', 'Spen', 'Spi1', 'Spib', 'Srebf1', 'Srebf2', 'Stat1', 'Stat2', 'Stat3', 'Stat4', 'Stat6', 'Taf1', 'Tbp', 'Tbx21', 'Tcf12', 'Tcf3', 'Tcf4', 'Tcf7', 'Tcf7l2', 'Tef', 'Tfdp1', 'Tfeb', 'Tgif1', 'Usf1', 'Usf2', 'Vezf1', 'Xbp1', 'Yy1', 'Zbtb18', 'Zeb1', 'Zfp652', 'Zfp740', 'Zfx']\n"
     ]
    }
   ],
   "source": [
    "# Jacobians\n",
    "TFs = adata_atac.var['TF'].values\n",
    "genes_of_interest = ['Spen', 'Notch2']\n",
    "genes_of_interest = [g.capitalize() for g in genes_of_interest]\n",
    "genes_of_interest = list(np.intersect1d(adata_rna_pred.var_names, np.union1d(TFs, genes_of_interest)))\n",
    "genes_of_interest.sort()\n",
    "print(len(genes_of_interest))\n",
    "print(genes_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/25\n",
      "Batch 2/25\n",
      "Batch 3/25\n",
      "Batch 4/25\n",
      "Batch 5/25\n",
      "Batch 6/25\n",
      "Batch 7/25\n",
      "Batch 8/25\n",
      "Batch 9/25\n",
      "Batch 10/25\n",
      "Batch 11/25\n",
      "Batch 12/25\n",
      "Batch 13/25\n",
      "Batch 14/25\n",
      "Batch 15/25\n",
      "Batch 16/25\n",
      "Batch 17/25\n",
      "Batch 18/25\n",
      "Batch 19/25\n",
      "Batch 20/25\n",
      "Batch 21/25\n",
      "Batch 22/25\n",
      "Batch 23/25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.mode = 'evaluation-fixed'\n",
    "adata_rna_pred = model.calculate_jacobians(adata_rna_pred, adata_atac_pred, dataloader, genes_of_interest, epsilon = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-silico gene perturbation\n",
    "One of the useful applications of DynaVelo is to perform in-silico gene perturbations and observe the resulting changes in RNA and motif velocities. This approach helps us understand how perturbing a gene can alter cell trajectories. Such insights are invaluable for identifying optimal perturbation targets to restore lost functions in diseases where normal trajectories have been disrupted. The `perturbed_genes` list specifies the genes for in-silico perturbations. If a gene is a TF, both its RNA expression and motif accessibility are set to the minimum value observed across all cells; otherwise, only RNA expression is perturbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0 / perturbed gene: Ahr\n",
      "idx: 1 / perturbed gene: Arid3a\n",
      "idx: 2 / perturbed gene: Arid3b\n",
      "idx: 3 / perturbed gene: Arid5a\n",
      "idx: 4 / perturbed gene: Arnt\n",
      "idx: 5 / perturbed gene: Arntl\n",
      "idx: 6 / perturbed gene: Atf1\n",
      "idx: 7 / perturbed gene: Atf2\n",
      "idx: 8 / perturbed gene: Atf4\n",
      "n_rep: 1\n",
      "idx: 9 / perturbed gene: Atf7\n",
      "idx: 10 / perturbed gene: Bach2\n",
      "idx: 11 / perturbed gene: Batf\n",
      "idx: 12 / perturbed gene: Bcl6\n",
      "idx: 13 / perturbed gene: Bhlhe40\n",
      "idx: 14 / perturbed gene: Bhlhe41\n",
      "n_rep: 1\n",
      "idx: 15 / perturbed gene: Cebpg\n",
      "idx: 16 / perturbed gene: Clock\n",
      "idx: 17 / perturbed gene: Creb1\n",
      "idx: 18 / perturbed gene: Creb3l2\n",
      "idx: 19 / perturbed gene: Crem\n",
      "n_rep: 1\n",
      "idx: 20 / perturbed gene: Ctcf\n",
      "n_rep: 1\n",
      "idx: 21 / perturbed gene: Cux1\n",
      "idx: 22 / perturbed gene: E2f1\n",
      "idx: 23 / perturbed gene: E2f2\n",
      "idx: 24 / perturbed gene: E2f3\n",
      "idx: 25 / perturbed gene: E2f4\n",
      "idx: 26 / perturbed gene: E2f5\n",
      "idx: 27 / perturbed gene: E2f7\n",
      "idx: 28 / perturbed gene: E2f8\n",
      "idx: 29 / perturbed gene: Ebf1\n",
      "idx: 30 / perturbed gene: Egr2\n",
      "n_rep: 1\n",
      "idx: 31 / perturbed gene: Elf1\n",
      "idx: 32 / perturbed gene: Elf2\n",
      "idx: 33 / perturbed gene: Elf4\n",
      "idx: 34 / perturbed gene: Elk3\n",
      "n_rep: 1\n",
      "idx: 35 / perturbed gene: Elk4\n",
      "idx: 36 / perturbed gene: Esr1\n",
      "n_rep: 1\n",
      "n_rep: 1\n",
      "idx: 37 / perturbed gene: Esrra\n",
      "idx: 38 / perturbed gene: Ets1\n",
      "idx: 39 / perturbed gene: Etv3\n",
      "n_rep: 1\n",
      "idx: 40 / perturbed gene: Etv6\n",
      "n_rep: 1\n",
      "idx: 41 / perturbed gene: Fli1\n",
      "idx: 42 / perturbed gene: Fos\n",
      "idx: 43 / perturbed gene: Fosb\n",
      "idx: 44 / perturbed gene: Foxj2\n",
      "idx: 45 / perturbed gene: Foxj3\n",
      "idx: 46 / perturbed gene: Foxk1\n",
      "n_rep: 1\n",
      "idx: 47 / perturbed gene: Foxk2\n",
      "idx: 48 / perturbed gene: Foxo1\n",
      "n_rep: 1\n",
      "idx: 49 / perturbed gene: Foxo3\n",
      "idx: 50 / perturbed gene: Foxp1\n",
      "idx: 51 / perturbed gene: Gabpa\n",
      "idx: 52 / perturbed gene: Gfi1\n",
      "idx: 53 / perturbed gene: Gmeb1\n",
      "idx: 54 / perturbed gene: Gmeb2\n",
      "idx: 55 / perturbed gene: Hif1a\n",
      "idx: 56 / perturbed gene: Hinfp\n",
      "idx: 57 / perturbed gene: Hltf\n",
      "idx: 58 / perturbed gene: Hmbox1\n",
      "idx: 59 / perturbed gene: Hsf1\n",
      "idx: 60 / perturbed gene: Id2\n",
      "idx: 61 / perturbed gene: Ikzf1\n",
      "idx: 62 / perturbed gene: Irf1\n",
      "idx: 63 / perturbed gene: Irf2\n",
      "n_rep: 1\n",
      "idx: 64 / perturbed gene: Irf3\n",
      "idx: 65 / perturbed gene: Irf4\n",
      "idx: 66 / perturbed gene: Irf5\n",
      "n_rep: 1\n",
      "idx: 67 / perturbed gene: Irf8\n",
      "idx: 68 / perturbed gene: Irf9\n",
      "idx: 69 / perturbed gene: Junb\n",
      "idx: 70 / perturbed gene: Klf12\n",
      "idx: 71 / perturbed gene: Klf13\n",
      "idx: 72 / perturbed gene: Klf3\n",
      "idx: 73 / perturbed gene: Klf4\n",
      "idx: 74 / perturbed gene: Klf6\n",
      "idx: 75 / perturbed gene: Klf8\n",
      "idx: 76 / perturbed gene: Lin54\n",
      "idx: 77 / perturbed gene: Max\n",
      "idx: 78 / perturbed gene: Maz\n",
      "idx: 79 / perturbed gene: Mbd2\n",
      "idx: 80 / perturbed gene: Mecp2\n",
      "idx: 81 / perturbed gene: Mef2a\n",
      "idx: 82 / perturbed gene: Mef2b\n",
      "idx: 83 / perturbed gene: Mef2c\n",
      "idx: 84 / perturbed gene: Mef2d\n",
      "idx: 85 / perturbed gene: Mga\n",
      "idx: 86 / perturbed gene: Mlxip\n",
      "idx: 87 / perturbed gene: Mnt\n",
      "idx: 88 / perturbed gene: Mtf1\n",
      "idx: 89 / perturbed gene: Mxi1\n",
      "idx: 90 / perturbed gene: Myb\n",
      "n_rep: 1\n",
      "n_rep: 1\n",
      "idx: 91 / perturbed gene: Mybl1\n",
      "idx: 92 / perturbed gene: Mybl2\n",
      "idx: 93 / perturbed gene: Myc\n",
      "idx: 94 / perturbed gene: Nfat5\n",
      "idx: 95 / perturbed gene: Nfatc1\n",
      "idx: 96 / perturbed gene: Nfatc2\n",
      "idx: 97 / perturbed gene: Nfatc3\n",
      "idx: 98 / perturbed gene: Nfe2l2\n",
      "idx: 99 / perturbed gene: Nfia\n",
      "idx: 100 / perturbed gene: Nfic\n",
      "n_rep: 1\n",
      "idx: 101 / perturbed gene: Nfkb1\n",
      "idx: 102 / perturbed gene: Nfkb2\n",
      "idx: 103 / perturbed gene: Nfya\n",
      "n_rep: 1\n",
      "idx: 104 / perturbed gene: Nfyb\n",
      "idx: 105 / perturbed gene: Nfyc\n",
      "idx: 106 / perturbed gene: Notch2\n",
      "idx: 107 / perturbed gene: Nr1d2\n",
      "idx: 108 / perturbed gene: Nr2c1\n",
      "idx: 109 / perturbed gene: Nr2c2\n",
      "idx: 110 / perturbed gene: Nr3c1\n",
      "idx: 111 / perturbed gene: Nr3c2\n",
      "idx: 112 / perturbed gene: Nr4a1\n",
      "idx: 113 / perturbed gene: Nr6a1\n",
      "idx: 114 / perturbed gene: Nrf1\n",
      "idx: 115 / perturbed gene: Patz1\n",
      "idx: 116 / perturbed gene: Pax5\n",
      "idx: 117 / perturbed gene: Pbx1\n",
      "idx: 118 / perturbed gene: Pbx2\n",
      "idx: 119 / perturbed gene: Pbx3\n",
      "idx: 120 / perturbed gene: Pknox1\n",
      "idx: 121 / perturbed gene: Pou2f1\n",
      "idx: 122 / perturbed gene: Pou2f2\n",
      "idx: 123 / perturbed gene: Pou6f1\n",
      "idx: 124 / perturbed gene: Prdm1\n",
      "idx: 125 / perturbed gene: Prdm4\n",
      "idx: 126 / perturbed gene: Rara\n",
      "idx: 127 / perturbed gene: Rbpj\n",
      "idx: 128 / perturbed gene: Rel\n",
      "idx: 129 / perturbed gene: Rela\n",
      "idx: 130 / perturbed gene: Relb\n",
      "idx: 131 / perturbed gene: Rest\n",
      "idx: 132 / perturbed gene: Rfx1\n",
      "idx: 133 / perturbed gene: Rfx3\n",
      "idx: 134 / perturbed gene: Rreb1\n",
      "idx: 135 / perturbed gene: Runx1\n",
      "idx: 136 / perturbed gene: Runx3\n",
      "n_rep: 2\n",
      "idx: 137 / perturbed gene: Smad2\n",
      "idx: 138 / perturbed gene: Smad3\n",
      "idx: 139 / perturbed gene: Smad4\n",
      "idx: 140 / perturbed gene: Sox5\n",
      "idx: 141 / perturbed gene: Sp1\n",
      "idx: 142 / perturbed gene: Sp2\n",
      "n_rep: 1\n",
      "idx: 143 / perturbed gene: Sp3\n",
      "idx: 144 / perturbed gene: Sp4\n",
      "idx: 145 / perturbed gene: Spen\n",
      "idx: 146 / perturbed gene: Spi1\n",
      "idx: 147 / perturbed gene: Spib\n",
      "idx: 148 / perturbed gene: Srebf1\n",
      "idx: 149 / perturbed gene: Srebf2\n",
      "idx: 150 / perturbed gene: Stat1\n",
      "idx: 151 / perturbed gene: Stat2\n",
      "idx: 152 / perturbed gene: Stat3\n",
      "idx: 153 / perturbed gene: Stat4\n",
      "idx: 154 / perturbed gene: Stat6\n",
      "idx: 155 / perturbed gene: Taf1\n",
      "idx: 156 / perturbed gene: Tbp\n",
      "idx: 157 / perturbed gene: Tbx21\n",
      "idx: 158 / perturbed gene: Tcf12\n",
      "idx: 159 / perturbed gene: Tcf3\n",
      "idx: 160 / perturbed gene: Tcf4\n",
      "idx: 161 / perturbed gene: Tcf7\n",
      "n_rep: 1\n",
      "idx: 162 / perturbed gene: Tcf7l2\n",
      "idx: 163 / perturbed gene: Tfdp1\n",
      "idx: 164 / perturbed gene: Tfeb\n",
      "idx: 165 / perturbed gene: Tgif1\n",
      "idx: 166 / perturbed gene: Usf1\n",
      "idx: 167 / perturbed gene: Usf2\n",
      "idx: 168 / perturbed gene: Vezf1\n",
      "idx: 169 / perturbed gene: Xbp1\n",
      "idx: 170 / perturbed gene: Yy1\n",
      "idx: 171 / perturbed gene: Zbtb18\n",
      "idx: 172 / perturbed gene: Zeb1\n",
      "idx: 173 / perturbed gene: Zfp652\n",
      "idx: 174 / perturbed gene: Zfp740\n",
      "idx: 175 / perturbed gene: Zfx\n"
     ]
    }
   ],
   "source": [
    "# In-silico gene perturbation\n",
    "TFs = adata_atac.var['TF'].values\n",
    "#idx_tfs_sub = np.where((adata_rna_pred[:, TFs].X.toarray()>0).sum(0)>1000)[0]\n",
    "#TFs_sub = TFs[idx_tfs_sub]\n",
    "perturbed_genes = ['Spen', 'Notch2']\n",
    "perturbed_genes = [g.capitalize() for g in perturbed_genes]\n",
    "perturbed_genes = list(np.intersect1d(adata_rna_pred.var_names, np.union1d(TFs, perturbed_genes)))\n",
    "perturbed_genes.sort()\n",
    "\n",
    "model.mode = 'evaluation-fixed'\n",
    "adata_rna_pred = model.predict_perturbation(adata_rna_pred, adata_atac_pred, dataloader, perturbed_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna_pred.write_h5ad(f\"/mnt/storage/Ben_data/analysis/outs/RNAMatrix/predicted/RNA_Matrix_Pred_{sample_name}.h5ad\")\n",
    "adata_atac_pred.write_h5ad(f\"/mnt/storage/Ben_data/analysis/outs/MotifMatrix/predicted/Motif_Matrix_Pred_{sample_name}.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynavelo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
